import os
import json
import logging
import random
from tqdm import tqdm
from collections import defaultdict
from typing import Tuple
from glob import glob

import pandas as pd
import numpy as np

from PIL import Image, ImageOps
import cv2

import torch
from torch import nn, Tensor
from torchvision import models
from torchvision.transforms import Compose
from torchvision.transforms import functional as F
from torchvision import transforms as T
from torchmetrics.detection.mean_ap import MeanAveragePrecision

import warnings
warnings.filterwarnings('ignore')

# Add these lines for Windows multiprocessing support
import multiprocessing
multiprocessing.freeze_support()

class_names = [
'palm']

FORMATS = (".jpeg", ".jpg", ".jp2", ".png", ".tiff", ".jfif", ".bmp", ".webp", ".heic")

transform = T.ToTensor()

class GestureDataset(torch.utils.data.Dataset):

    @staticmethod
    def __get_files_from_dir(pth: str, extns: Tuple):
        if not os.path.exists(pth):
            print(f"Dataset directory doesn't exist {pth}")
            return []
        files = [f for f in os.listdir(pth) if f.endswith(extns)]
        return files

    def __read_annotations(self, path):
        annotations_all = None
        exists_images = []
        for target in class_names:
            path_to_csv = os.path.join(path, f"{target}.json")
            if os.path.exists(path_to_csv):
                with open(path_to_csv, 'r') as f:
                    json_annotation = json.load(f)

                json_annotation = [dict(annotation, **{"name": f"{name}.jpg"}) for name, annotation in
                                   zip(json_annotation, json_annotation.values())]

                annotation = pd.DataFrame(json_annotation)

                annotation["target"] = target
                annotations_all = pd.concat([annotations_all, annotation], ignore_index=True)
                exists_images.extend(
                    self.__get_files_from_dir(os.path.join(self.path_images, target), FORMATS))
            else:
                if target != 'no_gesture':
                    print(f"Database for {target} not found")

        # Remove this line to prevent errors if annotations_all is None
        if annotations_all is None:
            raise ValueError("No annotations found in the dataset")

        annotations_all["exists"] = annotations_all["name"].isin(exists_images)

        annotations_all = annotations_all[annotations_all["exists"]]

        users = annotations_all["user_id"].unique()
        users = sorted(users)
        random.Random(42).shuffle(users)
        train_users = users[:int(len(users) * 0.8)]
        val_users = users[int(len(users) * 0.8):]

        annotations_all = annotations_all.copy()

        if self.is_train:
            annotations_all = annotations_all[annotations_all["user_id"].isin(train_users)]
        else:
            annotations_all = annotations_all[annotations_all["user_id"].isin(val_users)]

        return annotations_all

    def __init__(self, path_annotation, path_images, is_train, transform=None):
        self.is_train = is_train
        self.transform = transform
        self.path_annotation = path_annotation
        self.path_images = path_images
        self.transform = transform
        self.labels = {label: num for (label, num) in
                       zip(class_names, range(len(class_names)))}
        self.annotations = self.__read_annotations(self.path_annotation)

    def __len__(self):
        return self.annotations.shape[0]

    def get_sample(self, index: int):
        row = self.annotations.iloc[[index]].to_dict('records')[0]
        image_pth = os.path.join(self.path_images, row["target"], row["name"])
        image = Image.open(image_pth).convert("RGB")

        labels = torch.LongTensor([self.labels[label] for label in row["labels"]])

        target = {}
        width, height = image.size

        bboxes = []

        for bbox in row["bboxes"]:
            x1, y1, w, h = bbox
            bbox_abs = [x1 * width, y1 * height, (x1 + w) * width, (y1 + h) * height]
            bboxes.append(bbox_abs)

        target["labels"] = labels
        target["boxes"] = torch.as_tensor(bboxes, dtype=torch.float32)
        target["orig_size"] = torch.as_tensor([int(height), int(width)])

        return image, target

    def __getitem__(self, index: int):
        image, target = self.get_sample(index)
        if self.transform:
            image = self.transform(image)
        return image, target

# Setting some constants for training
random_seed = 42
num_classes = len(class_names)
batch_size = 16
num_epoch = 15
torch.manual_seed(random_seed)
np.random.seed(random_seed)
random.seed(random_seed)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def collate_fn(batch):
    batch_targets = list()
    images = list()

    for b in batch:
        images.append(b[0])
        batch_targets.append({"boxes": b[1]["boxes"],
                              "labels": b[1]["labels"]})
    return images, batch_targets

def create_datasets(images_path='dataset/subsample', 
                    annotations_path='dataset/ann_subsample'):
    """
    Helper function to create train and test datasets with error checking
    """
    # Validate dataset paths
    if not os.path.exists(images_path):
        raise FileNotFoundError(f"Images path does not exist: {images_path}")
    
    if not os.path.exists(annotations_path):
        raise FileNotFoundError(f"Annotations path does not exist: {annotations_path}")

    train_data = GestureDataset(path_images=images_path,
                                path_annotation=annotations_path,
                                is_train=True, transform=transform)

    test_data = GestureDataset(path_images=images_path,
                               path_annotation=annotations_path,
                               is_train=False, transform=transform)
    
    return train_data, test_data

def create_dataloaders(train_data, test_data, batch_size=16):
    """
    Helper function to create data loaders
    """
    train_dataloader = torch.utils.data.DataLoader(
        train_data, 
        batch_size=batch_size, 
        collate_fn=collate_fn, 
        shuffle=True, 
        num_workers=0  # Important for Windows compatibility
    )
    
    test_dataloader = torch.utils.data.DataLoader(
        test_data, 
        batch_size=batch_size, 
        collate_fn=collate_fn, 
        shuffle=True, 
        num_workers=0  # Important for Windows compatibility
    )
    
    return train_dataloader, test_dataloader

def initialize_model(num_classes):
    """
    Initialize the object detection model
    """
    model = models.detection.ssdlite320_mobilenet_v3_large(
        num_classes=num_classes + 1,  # +1 for background 
        pretrained_backbone=True
    )
    model.to(device)
    return model

def configure_optimizer(model, lr=0.005, momentum=0.9, weight_decay=5e-4):
    """
    Configure optimizer and learning rate scheduler
    """
    optimizer = torch.optim.SGD(
        model.parameters(), 
        lr=lr, 
        momentum=momentum, 
        weight_decay=weight_decay
    )

    warmup_factor = 1.0 / 1000
    warmup_iters = 1000  # You might want to adjust this

    lr_scheduler_warmup = torch.optim.lr_scheduler.LinearLR(
        optimizer, 
        start_factor=warmup_factor, 
        total_iters=warmup_iters
    )
    
    return optimizer, lr_scheduler_warmup

def evaluate_model(model, test_dataloader, device):
    """
    Evaluate model performance using Mean Average Precision
    """
    model.eval()
    with torch.no_grad():
        mapmetric = MeanAveragePrecision()
        
        for images, targets in test_dataloader:
            images = list(image.to(device) for image in images)
            output = model(images)
            
            for pred in output:
                for key, value in pred.items():
                    pred[key] = value.cpu()
                    
            mapmetric.update(output, targets)

    metrics = mapmetric.compute()
    return metrics

def train_model(model, train_dataloader, test_dataloader, optimizer, 
                lr_scheduler, num_epochs=15, device=device):
    """
    Main training loop
    """
    os.makedirs('checkpoints', exist_ok=True)
    
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        total_batches = 0
        
        for images, targets in tqdm(train_dataloader, desc=f'Epoch {epoch}'):
            images = list(image.to(device) for image in images)
            
            # Move targets to device
            for target in targets:
                for key, value in target.items():
                    target[key] = value.to(device)
            
            # Zero gradients
            optimizer.zero_grad()
            
            # Forward pass
            loss_dict = model(images, targets)
            losses = sum(loss for loss in loss_dict.values())
            
            # Backward pass
            losses.backward()
            optimizer.step()
            lr_scheduler.step()
            
            total_loss += losses.item()
            total_batches += 1
        
        # Evaluate after each epoch
        metrics = evaluate_model(model, test_dataloader, device)
        
        print(f"Epoch {epoch}: Loss = {total_loss/total_batches:.4f}, mAP = {metrics['map']:.4f}")
        
        # Save checkpoint
        torch.save(model.state_dict(), f'checkpoints/model_epoch_{epoch}.pth')
    
    return model

def main():
    # Suppress warnings and set random seeds for reproducibility
    warnings.filterwarnings('ignore')
    multiprocessing.freeze_support()

    try:
        # Create datasets
        train_data, test_data = create_datasets()
        
        # Create data loaders
        train_dataloader, test_dataloader = create_dataloaders(train_data, test_data)
        
        # Initialize model
        model = initialize_model(num_classes=len(class_names))
        
        # Configure optimizer and learning rate scheduler
        optimizer, lr_scheduler = configure_optimizer(model)
        
        # Train the model
        trained_model = train_model(
            model, 
            train_dataloader, 
            test_dataloader, 
            optimizer, 
            lr_scheduler
        )
        
        print("Training completed successfully!")
    
    except Exception as e:
        print(f"An error occurred during training: {e}")
        import traceback
        traceback.print_exc()

# Ensure this is the standard Python multiprocessing safe pattern
if __name__ == '__main__':
    main()